# Kuma Depth Opt

リアルタイムカメラの深度推定とストリーミングを行うFastAPIベースのウェブアプリケーションです。

## 機能

- ウェブブラウザを通じたリアルタイムカメラのストリーミング
- Depth Anythingモデルを使用したリアルタイム深度推定
- 通常のカメラビュー、深度マップ、深度グリッドの3種類の表示モード
- パフォーマンス統計情報のリアルタイム表示（FPSと遅延時間）

## ディレクトリ構成

```
kuma_depth_opt/
├── config.json                # アプリケーション設定ファイル
├── readme.md                  # このREADMEファイル
├── requirements.txt           # 依存パッケージリスト
├── simple_fastapi_camera.py   # メインアプリケーションファイル
├── utils.py                   # ユーティリティ関数
├── __pycache__/               # Pythonキャッシュディレクトリ
│   └── utils.cpython-310.pyc  # コンパイル済みPythonファイル
└── depth_processor/           # 深度処理モジュール
    ├── __init__.py            # モジュール初期化
    ├── depth_model.py         # 深度推定モデルの実装
    ├── point_cloud.py         # 点群処理用ユーティリティ
    └── visualization.py       # 深度マップの可視化関数
```

## 必要条件

- Python 3.8以上
- OpenCV
- FastAPI
- Uvicorn
- NumPy
- その他 requirements.txt に記載されている依存パッケージ

## インストール方法

1. このリポジトリをクローンまたはダウンロードします。

2. 必要なパッケージをインストールします：

```bash
pip install -r requirements.txt
```

## 実行方法

以下のコマンドでアプリケーションを起動します：

```bash
python simple_fastapi_camera.py
```

アプリケーションが起動したら、ブラウザで以下のURLにアクセスします：

```
http://localhost:8888
```

## インターフェース説明

Webインターフェースには以下の4つのビューがあります：

1. **Camera Stream** - 通常のカメラ映像
2. **Depth Map** - 深度推定のヒートマップ表示
3. **Depth Grid** - 深度をグリッド形式で表示
4. **Top-Down View** - 3D空間を俯瞰した上からの視点表示

また、パフォーマンス統計情報（FPSと遅延時間）も表示されます。

## パフォーマンス最適化

アプリケーションは以下の点で最適化されています：

- マルチスレッド処理でカメラキャプチャと深度推定を並行実行
- 効率的なメモリ管理
- 低レイテンシのための最適化されたストリーミング
- エラー時の自動カメラリセット機能

## 注意点

- カメラが正しく接続されていることを確認してください
- 十分なCPU/GPU性能がないと、推論速度が低下する可能性があります


----

[![Depth Anything: Accelerating Monocular Depth Perception](https://tse1.mm.bing.net/th?id=OIP.SbIO7cLsmvgcyXZhDMs9mQHaCo\&cb=iwc1\&pid=Api)](https://learnopencv.com/depth-anything/)

以下は、Depth Anythingの出力形式、その意味、そして絶対距離を計算するための方法について整理した資料です。

---

# Depth Anything 出力と絶対距離の計算方法

## 📌 出力形式と意味

* **出力形式**: Depth Anythingは、入力画像と同じ解像度の1チャンネルのfloat32型テンソルを出力します。
* **値の意味**: 各ピクセルの値は **視差（disparity）** を表しており、これは「1 / 深度（距離）」に相当します。&#x20;
* **正規化**: 学習時には、深度値を視差空間に変換し、各深度マップ内で0から1の範囲に正規化しています。&#x20;

## ⚠️ 注意点

* **相対値である**: 出力は相対的な「近さ」を示すものであり、絶対的な距離を直接得ることはできません。
* **スケーリングが必要**: 絶対距離を求めるには、既知の距離を持つ物体を基準にスケーリングを行う必要があります。
* **逆数変換の注意**: 出力が視差であるため、単純に逆数を取るだけでは正確な距離を得ることはできません。スケーリングとシフトの調整が必要です。

## 🧮 絶対距離を計算する方法

Depth Anythingの出力を絶対距離（メートル単位）に変換するには、以下の手順を踏む必要があります。

1. **既知の距離を持つ参照点を選定**: 画像内で実際の距離が分かっている点（例：特定の物体までの距離が5メートル）を選びます。

2. **スケーリング係数の計算**: 選定した参照点の出力値（視差）を用いて、スケーリング係数を計算します。

   例えば、参照点の出力値が3で、実際の距離が5メートルの場合：

   ```
   スケーリング係数 = 実際の距離 × 出力値 = 5 × 3 = 15
   ```

3. **全体の距離マップの計算**: スケーリング係数を用いて、全体の距離マップを計算します。

   ```
   実際の距離マップ = スケーリング係数 / 出力値マップ
   ```

   この計算により、各ピクセルの絶対距離を推定できます。

## 📝 まとめ

* **出力値の意味**: Depth Anythingの出力は視差（1 / 距離）を表す相対的な値です。
* **絶対距離の取得**: 既知の距離を持つ参照点を用いてスケーリング係数を計算し、全体の距離マップを推定します。
* **注意点**: 出力は相対値であり、単純な逆数変換では正確な距離を得ることはできません。スケーリングとシフトの調整が必要です。

この方法により、Depth Anythingの出力を実際の距離情報として活用することが可能になります。
