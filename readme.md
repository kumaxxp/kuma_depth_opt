# Kuma Depth Opt

リアルタイムカメラの深度推定とストリーミングを行うFastAPIベースのウェブアプリケーションです。

## 機能

- ウェブブラウザを通じたリアルタイムカメラのストリーミング
- Depth Anythingモデルを使用したリアルタイム深度推定
- 通常のカメラビュー、深度マップ、深度グリッドの3種類の表示モード
- パフォーマンス統計情報のリアルタイム表示（FPSと遅延時間）

## ディレクトリ構成

```
kuma_depth_opt/
├── config.json                # アプリケーション設定ファイル
├── readme.md                  # このREADMEファイル
├── requirements.txt           # 依存パッケージリスト
├── simple_fastapi_camera.py   # メインアプリケーションファイル
├── utils.py                   # ユーティリティ関数
├── __pycache__/               # Pythonキャッシュディレクトリ
│   └── utils.cpython-310.pyc  # コンパイル済みPythonファイル
└── depth_processor/           # 深度処理モジュール
    ├── __init__.py            # モジュール初期化
    ├── depth_model.py         # 深度推定モデルの実装
    ├── point_cloud.py         # 点群処理用ユーティリティ
    └── visualization.py       # 深度マップの可視化関数
```

## 必要条件

- Python 3.8以上
- OpenCV
- FastAPI
- Uvicorn
- NumPy
- その他 requirements.txt に記載されている依存パッケージ

## インストール方法

1. このリポジトリをクローンまたはダウンロードします。

2. 必要なパッケージをインストールします：

```bash
pip install -r requirements.txt
```

## 実行方法

以下のコマンドでアプリケーションを起動します：

```bash
python simple_fastapi_camera.py
```

アプリケーションが起動したら、ブラウザで以下のURLにアクセスします：

```
http://localhost:8888
```

## インターフェース説明

Webインターフェースには以下の4つのビューがあります：

1. **Camera Stream** - 通常のカメラ映像
2. **Depth Map** - 深度推定のヒートマップ表示
3. **Depth Grid** - 深度をグリッド形式で表示
4. **Top-Down View** - 3D空間を俯瞰した上からの視点表示

また、パフォーマンス統計情報（FPSと遅延時間）も表示されます。

## トップダウンビューテストツール

実際のカメラなしでトップダウンビュー機能をテストするためのツールセットが用意されています。これらのツールを使うと、圧縮深度データからポイントクラウドや占有グリッドを生成し、様々なパラメータ設定での結果を比較できます。

### テストツールの構成

- `test_top_view.py`: 基本的なトップダウンビューのテスト
- `generate_test_data.py`: 様々なシーン（空部屋、障害物、廊下など）のテストデータ生成
- `compare_parameters.py`: 異なるパラメータ設定での結果比較
- `TOP_VIEW_TEST_README.md`: 詳細な使用方法

### テストツールの使い方

1. **テスト用データの生成**:
   ```bash
   python generate_test_data.py --output-dir test_data
   ```

2. **基本的なトップダウンビューのテスト**:
   ```bash
   python test_top_view.py --csv test_data/obstacle_grid.csv --save-dir results
   ```

3. **パラメータ比較テスト**:
   ```bash
   python compare_parameters.py --csv test_data/corridor_grid.csv --save-dir comparison
   ```

詳細な使用方法は `TOP_VIEW_TEST_README.md` を参照してください。

### テストツールの主な目的と利点

- **カメラレス開発**: 実際のカメラがなくてもデータを用意すれば開発とテストが可能
- **パラメータ最適化**: 様々な設定（グリッド解像度、高さ閾値など）を短時間で比較可能
- **再現性の確保**: 同じ深度データで何度も実験ができるため、変更の効果を正確に評価可能
- **異なるシナリオの検証**: 生成したテストデータで様々な環境（障害物、階段など）での動作を確認可能
- **視覚的フィードバック**: 点群分布、占有グリッド、分類結果を視覚的に確認できる

### 主なパラメータと調整のポイント

- **grid_resolution** (0.05-0.2m): 小さいほど細かいグリッドになるが計算負荷が増加
- **height_threshold** (0.1-0.3m): 床と障害物を区別する高さの閾値
- **scaling_factor** (5.0-15.0): 相対深度から絶対深度への変換係数
- **グリッドサイズ**: 解像度に応じて調整（例: 4m÷解像度）

圧縮データを使用したトップダウンビューの生成は処理負荷を抑えながら全体的な環境認識を可能にし、リアルタイム性能と視覚品質のバランスを取る上で重要です。

### テスト結果の例と最適化事例

テストツールを使用して見つかった主な最適化ポイントは以下の通りです：

1. **高さ閾値の適応的決定**:
   - 問題: 固定閾値では様々な環境で床と障害物の区別が困難
   - 解決策: 点群のY値分布の5パーセンタイルと75パーセンタイルを活用して適応的に閾値を決定
   - 結果: 異なる環境でも安定した床検出が可能に

2. **グリッド解像度の最適化**:
   - 問題: 高解像度は詳細だが処理負荷が高く、低解像度は障害物検出が不十分
   - テスト結果: 圧縮データでは0.08m前後が処理速度と検出精度のバランスが最適
   - 結果: 10FPS以上を維持しながら十分な障害物検出が可能に

3. **カメラパラメータの調整**:
   - 問題: 圧縮データに標準カメラパラメータを適用すると視野角が狭くなる
   - 解決策: fx、fyパラメータに0.8の係数を掛けて視野角を広げる
   - 結果: 圧縮データでも広い視野をカバーできるように

テストツールを活用することで、このような具体的な最適化が可能になり、システム全体のパフォーマンスと視覚的な品質が向上します。結果の例として、同じ深度データに対して異なるパラメータ設定で生成したトップダウンビューの比較画像をご覧いただけます。

## パフォーマンス最適化

アプリケーションは以下の点で最適化されています：

- マルチスレッド処理でカメラキャプチャと深度推定を並行実行
- 効率的なメモリ管理
- 低レイテンシのための最適化されたストリーミング
- エラー時の自動カメラリセット機能

## 注意点

- カメラが正しく接続されていることを確認してください
- 十分なCPU/GPU性能がないと、推論速度が低下する可能性があります


----

[![Depth Anything: Accelerating Monocular Depth Perception](https://tse1.mm.bing.net/th?id=OIP.SbIO7cLsmvgcyXZhDMs9mQHaCo\&cb=iwc1\&pid=Api)](https://learnopencv.com/depth-anything/)

以下は、Depth Anythingの出力形式、その意味、そして絶対距離を計算するための方法について整理した資料です。

---

# Depth Anything 出力と絶対距離の計算方法

## 📌 出力形式と意味

* **出力形式**: Depth Anythingは、入力画像と同じ解像度の1チャンネルのfloat32型テンソルを出力します。
* **値の意味**: 各ピクセルの値は **視差（disparity）** を表しており、これは「1 / 深度（距離）」に相当します。&#x20;
* **正規化**: 学習時には、深度値を視差空間に変換し、各深度マップ内で0から1の範囲に正規化しています。&#x20;

## ⚠️ 注意点

* **相対値である**: 出力は相対的な「近さ」を示すものであり、絶対的な距離を直接得ることはできません。
* **スケーリングが必要**: 絶対距離を求めるには、既知の距離を持つ物体を基準にスケーリングを行う必要があります。
* **逆数変換の注意**: 出力が視差であるため、単純に逆数を取るだけでは正確な距離を得ることはできません。スケーリングとシフトの調整が必要です。

## 🧮 絶対距離を計算する方法

Depth Anythingの出力を絶対距離（メートル単位）に変換するには、以下の手順を踏む必要があります。

1. **既知の距離を持つ参照点を選定**: 画像内で実際の距離が分かっている点（例：特定の物体までの距離が5メートル）を選びます。

2. **スケーリング係数の計算**: 選定した参照点の出力値（視差）を用いて、スケーリング係数を計算します。

   例えば、参照点の出力値が3で、実際の距離が5メートルの場合：

   ```
   スケーリング係数 = 実際の距離 × 出力値 = 5 × 3 = 15
   ```

3. **全体の距離マップの計算**: スケーリング係数を用いて、全体の距離マップを計算します。

   ```
   実際の距離マップ = スケーリング係数 / 出力値マップ
   ```

   この計算により、各ピクセルの絶対距離を推定できます。

## 📝 まとめ

* **出力値の意味**: Depth Anythingの出力は視差（1 / 距離）を表す相対的な値です。
* **絶対距離の取得**: 既知の距離を持つ参照点を用いてスケーリング係数を計算し、全体の距離マップを推定します。
* **注意点**: 出力は相対値であり、単純な逆数変換では正確な距離を得ることはできません。スケーリングとシフトの調整が必要です。

この方法により、Depth Anythingの出力を実際の距離情報として活用することが可能になります。

## ライセンスと謝辞

このプロジェクトは、以下のオープンソースプロジェクトを利用しています：

- **Depth Anything**: 単眼深度推定モデル ©Meta AI Research 2024
  - ライセンス: Apache License 2.0
  - 参照: [Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://depth-anything.github.io/)

- **OpenCV**: コンピュータビジョンライブラリ
  - ライセンス: Apache License 2.0

- **FastAPI**: 高性能ウェブフレームワーク
  - ライセンス: MIT License

トップダウンビューテストツールを含む本プロジェクトのコード（Depth Anythingモデル自体を除く）は、MITライセンスの下で利用可能です。商用・非商用目的を問わず自由に使用できますが、著作権表示と許諾表示を含める必要があります。

## 連絡先

質問やフィードバックがありましたら、以下までご連絡ください：
[プロジェクト管理者のメールアドレスや連絡先情報]
